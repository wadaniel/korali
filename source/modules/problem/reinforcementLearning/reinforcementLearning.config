{
  
  "Module Data":
  {
    "Class Name": "ReinforcementLearning",
    "Namespace": ["korali", "problem"],
    "Parent Class Name": "Problem"
  },

 "Configuration Settings":
 [
   {
    "Name": [ "Agents Per Environment" ],
    "Type": "size_t",
    "Description": "Number of agents in a given environment. All agents share the same policy ."
   },
   {
    "Name": [ "Environment Count" ],
    "Type": "size_t",
    "Description": "Maximum number of different types of environments."
   },
   {
    "Name": [ "Environment Function" ],
    "Type": "std::function<void(korali::Sample&)>",
    "Description": "Function to initialize and run an episode in the environment."
   },
   {
    "Name": [ "Actions Between Policy Updates" ],
    "Type": "size_t",
    "Description": "Number of actions to take before requesting a new policy."
   },
   {
    "Name": [ "Testing Frequency" ],
    "Type": "size_t",
    "Description": "Number of episodes after which the policy will be tested."
   },
   {
    "Name": [ "Policy Testing Episodes" ],
    "Type": "size_t",
    "Description": "Number of test episodes to run the policy (without noise) for, for which the average sum of rewards will serve to evaluate the termination criteria."
   },
   {
    "Name": [ "Custom Settings" ],
    "Type": "knlohmann::json",
    "Description": "Any used-defined settings required by the environment."
   },
   {
   "Name": [ "Observations",  "States" ],
   "Type": "std::vector<std::vector<std::vector<float>>>",
   "Description": "Vector containing the states of the observed trajectories."
   },
   {
   "Name": [ "Observations", "Actions" ],
   "Type": "std::vector<std::vector<std::vector<float>>>",
   "Description": "Vector containing the actions of the observed trajectories."
   },
   {
   "Name": [ "Observations", "Features" ],
   "Type": "std::vector<std::vector<std::vector<float>>>",
   "Description": "Vector containing the features corresponding to the observed state action pairs."
   }

 ],

 "Available Operations":
 [
  {
    "Name": "Run Training Episode",
    "Description": "Runs the environment and receives the state and rewards and provides training actions (policy + exploratory noise) for an entire episode.",
    "Function": "runTrainingEpisode"
  },
  {
    "Name": "Run Testing Episode",
    "Description": "Runs the environment and receives the state and rewards and provides testing actions (policy only) for an entire episode.",
    "Function": "runTestingEpisode"
  }
 ],

 "Compatible Solvers": [ "Agent" ],

 "Variables Configuration":
 [
   {
    "Name": [ "Type" ],
    "Type": "std::string",
    "Options": [
                { "Value": "State", "Description": "The variable describes a state." },
                { "Value": "Action", "Description": "The variable describes an action." }
               ],
    "Description": "Indicates if the variable belongs to the state or action vector."
   },
   {
   "Name": [ "Lower Bound" ],
   "Type": "float",
   "Description": "Lower bound for the variable's value."
  },
  {
   "Name": [ "Upper Bound" ],
   "Type": "float",
   "Description": "Upper bound for the variable's value."
  }
 ],

  "Internal Settings":
 [
   {
    "Name": [ "Action Vector Size" ],
    "Type": "size_t",
    "Description": "Stores the dimension of the action space."
   },
   {
    "Name": [ "State Vector Size" ],
    "Type": "size_t",
    "Description": "Stores the dimension of the state space."
   },
   {
    "Name": [ "Action Vector Indexes" ],
    "Type": "std::vector<size_t>",
    "Description": "Stores the indexes of the variables that constitute the action vector."
   },
   {
    "Name": [ "State Vector Indexes" ],
    "Type": "std::vector<size_t>",
    "Description": "Stores the indexes of the number of variables that constitute the action vector."
   },
   {
    "Name": [ "Number Observed Trajectories" ],
    "Type": "size_t",
    "Description": "Stores the number of observed trajectories."
   },
   {
    "Name": [ "Feature Vector Size" ],
    "Type": "size_t",
    "Description": "The number of features that are observed to compute the reward."
   },
   {
    "Name": [ "Total Observed State Action Pairs" ],
    "Type": "size_t",
    "Description": "The total number of observed state action pairs."
   }
 ],

 "Module Defaults":
 {
   "Agents Per Environment": 1,
   "Environment Count" : 1,
   "Testing Frequency" : 0,
   "Policy Testing Episodes": 10,
   "Actions Between Policy Updates": 0,
   "Custom Settings": {}
 },

  "Variable Defaults":
 {
   "Type": "State",
   "Lower Bound": -Infinity,
   "Upper Bound": Infinity
 }

}
