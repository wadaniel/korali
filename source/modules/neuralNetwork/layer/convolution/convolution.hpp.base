#pragma once

#include "modules/neuralNetwork/layer/layer.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  /********************************************************
   * Engine specific members
   *******************************************************/

  /**
   * @brief Pre-calculated value for Mini-Batch Size
   */
  ssize_t N;

  /**
   * @brief Pre-calculated value for Input Channels
   */
  ssize_t IC;

  /**
   * @brief Pre-calculated value for Input Image Height
   */
  ssize_t IH;

  /**
   * @brief Pre-calculated value for Input Image Width
   */
  ssize_t IW;

  /**
   * @brief Pre-calculated value for Output Channels
   */
  ssize_t OC;

  /**
   * @brief Pre-calculated value for Output Image Height
   */
  ssize_t OH;

  /**
   * @brief Pre-calculated value for Output Image Width
   */
  ssize_t OW;

  /**
   * @brief Pre-calculated value for Kernel Image Height
   */
  ssize_t KH;

  /**
   * @brief Pre-calculated value for Kernel Image Width
   */
  ssize_t KW;

  /**
   * @brief Pre-calculated values for padding left
   */
  ssize_t PL;

  /**
   * @brief Pre-calculated values for padding right
   */
  ssize_t PR;

  /**
   * @brief Pre-calculated values for padding top
   */
  ssize_t PT;

  /**
   * @brief Pre-calculated values for padding bottom
   */
  ssize_t PB;

  /**
   * @brief Pre-calculated values for horizontal stride
   */
  ssize_t SH;

  /**
   * @brief Pre-calculated values for vertical stride
   */
  ssize_t SV;

#ifdef _KORALI_USE_ONEDNN

  /**
   * @brief Memory descriptor for the 2D mapping of the scalar input channels
   */
  dnnl::memory::desc _srcMemDesc;

  /**
   * @brief Memory descriptor for the 2D mapping of the scalar output channels
   */
  dnnl::memory::desc _dstMemDesc;

  /**
   * @brief oneDNN Memory object descriptor to contain the weights of inner product with incoming channels
   */
  dnnl::memory _weightsMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the weights of inner product with incoming channels
   */
  dnnl::memory _weightsReorderMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the bias to add to incoming channels
   */
  dnnl::memory _biasMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the gradient of the weights
   */
  dnnl::memory _weightsGradientMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the gradient of the biases
   */
  dnnl::memory _biasGradientMem;

  /**
   * @brief oneDNN primitive attributes that describe the forward convolution primitive
   */
  dnnl::convolution_forward::primitive_desc _forwardConvolutionPrimitiveDesc;

  /**
   * @brief oneDNN primitive to run the inner product + bias addition operation
   */
  dnnl::primitive _forwardConvolutionPrimitive;

  /**
   * @brief oneDNN Arguments for the backward propagation of the gradient wrt Data
   */
  std::unordered_map<int, dnnl::memory> _backwardDataArgs;

  /**
   * @brief oneDNN primitive for the backward propagation of the gradient wrt Data
   */
  dnnl::primitive _backwardDataPrimitive;

  /**
   * @brief oneDNN primitive for the backward propagation of the gradient wrt Weights and Biases
   */
  dnnl::primitive _backwardWeightsPrimitive;

#endif

  void copyHyperparameterPointers(Layer *dstLayer) override;
  void initialize() override;
  std::vector<float> generateInitialHyperparameters() override;
  void createHyperparameterMemory() override;
  void createForwardPipeline() override;
  void createBackwardPipeline() override;
  void forwardData(const size_t t) override;

  void setHyperparameters(float *hyperparameters) override;
  void getHyperparameters(float *hyperparameters) override;
  void getHyperparameterGradients(float *gradient) override;
  void backwardData(const size_t t) override;
  void backwardHyperparameters(const size_t t) override;
};

__endNamespace__;
